{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 컨볼루션 신경망(Convolution Neural Network)\n",
    "\n",
    "1장에서 각각의 layer가 완전히 연결되어 있는 dense neural network를 통해 MNIST 필기체 글자 dataset을 분류했다.\n",
    "입력 이미지의 각 픽셀들을 784의 입력 뉴런으로 할당했다. 이때 공간 구조, 관계 정보를 활용하지 않았다. 즉 1차원 벡터로 표현하면서\n",
    "지역 공간 구조가 사라졌다.\n",
    "\n",
    "`Convolution Nerual Network(CNN)`은 공간정보를 활용하기 때문에 이미지 분류에 아주 적합하다.\n",
    "\n",
    "\n",
    "## 심층 컨볼루션 신경망(Deep Convolution Neural Network)DCNN\n",
    "심층 컨볼루션 신경망은 여러 신경망 계층으로 구선되며 `Convolution` 과 `pooling`이라는 두 유형의 계층이 번갈아 가며 사용된다.\n",
    "마지막 단계는 일반적으로 하나 이상의 완전 연결 계층으로 구성된다.\n",
    "\n",
    "## Convolution의 세가지 키 : Receptive Field, 가중치 공유, pooling\n",
    "\n",
    "### Receptive Field\n",
    "지역수용필드라고 부른다. 이미지 또는 다른 형태의 데이터에 들어 있는 공간 정보를 보존하려면 각 이미지를 픽셀 행렬로 표시하면 편리하다.\n",
    "지역구조를 인코딩하는 간단한 방법은 입력 뉴런의 부분 행렬을 다음 계층에 있는 1개의 은닉 뉴런으로 연결하는 것이다. 이때 1개의 은닉 뉴런을\n",
    "`Receptive Field`라고 하며 이 작업을 `Convolution`이라고 한다.\n",
    "\n",
    "부분행렬의 크기는 `커널 크기`라고 한다. 컨볼루션의 각 단계에서 커널이 이동하는 픽셀 개수를 `스트라이드길이`라고 한다.\n",
    "\n",
    "예시 : \n",
    "MNIST 이미지를 처리하기 위해 28 * 28 입력 뉴런으로 시작한 다음 은닉층에서 24 * 24 뉴런크기를 갖는(5 * 5의 스트라이드) k개의 특징맵을 불러올 수 있다.\n",
    "\n",
    "\n",
    "### 가중치 공유 및 편향\n",
    "동일한 특징을 감지하는 기능을 통해 입력 이미지에 배치된 위치와 독립적으로 학습하기 위해서 은닉층의 모든 뉴런에 대해 동일한 가중치와 편향을 사용할 수 있다.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "```\n",
    "\n",
    "하나의 입력 채널로 28 * 28이미지에 3 * 3 컨볼루션을 적용해 32개의 출력 채널을 생성함\n",
    "\n",
    "### pooling layer\n",
    "특징 맵의 출력을 요약하기 위해 사용한다. max-pooling과 avg-pooling이 있다.\n",
    "\n",
    "최댓값 풀링 예제 자리\n",
    "\n",
    "\n",
    "## DCNN의 예시로 Tensorflow 에서의 LeNet코드\n",
    "\n",
    "```python\n",
    "layers.Convolution2D(20, (5, 5), activation('relu'), input_shape=input_shape)\n",
    "```\n",
    "\n",
    "첫 번째 매개변수는 컨볼루션의 출력 필터 수이고 다음 튜플은 각 필터의 확장이다.\n",
    "\n",
    "### 선택적 매개변수 padding\n",
    "- padding=\"valid\"의 경우 : 입력과 필터가 완전히 겹치는 경우에만 연산을 진행(출력의 크기가 입력의 크기보다 작음)\n",
    "- padding=\"same\"의 경우 : 입력과 필터가 완전히 겹치지 않는 경우에 대해서도 연산을 진행함(출력의 크기는 입력의 크기와 동일하다)\n",
    "\n",
    "```python\n",
    "layers.MaxPooling2D(pool_size=(2, 2), stride(2, 2))\n",
    "```\n",
    "(2, 2)는 이미지가 수직 및 수평으로 축소되는 인자를 나타내며 각 차원에 대해서 이미지를 절반으로 줄인다. 스트라이드는 (2, 2)를 처리할 때 사용하는 스트라이드다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "\n",
    "#define the convnet \n",
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = models.Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(layers.Convolution2D(20, (5, 5), activation='relu',\n",
    "\t\t\tinput_shape=input_shape))\n",
    "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
    "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# Flatten => RELU layers\n",
    "\t\tmodel.add(layers.Flatten())\n",
    "\t\tmodel.add(layers.Dense(500, activation='relu'))\n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(layers.Dense(classes, activation=\"softmax\"))\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "VALIDATION_SPLIT=0.90\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# normalize\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# cast\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# use TensorBoard, princess Aurora!\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# fit \n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
    "\t\tcallbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">400,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │           \u001b[38;5;34m520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │        \u001b[38;5;34m25,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m400,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,080</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,080\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,080</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,080\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.8087 - loss: 0.6437 - val_accuracy: 0.9727 - val_loss: 0.0885\n",
      "Epoch 2/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9753 - loss: 0.0775 - val_accuracy: 0.9801 - val_loss: 0.0630\n",
      "Epoch 3/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9857 - loss: 0.0437 - val_accuracy: 0.9836 - val_loss: 0.0529\n",
      "Epoch 4/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9900 - loss: 0.0346 - val_accuracy: 0.9851 - val_loss: 0.0524\n",
      "Epoch 5/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9908 - loss: 0.0304 - val_accuracy: 0.9856 - val_loss: 0.0480\n",
      "Epoch 6/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9947 - loss: 0.0170 - val_accuracy: 0.9871 - val_loss: 0.0448\n",
      "Epoch 7/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0122 - val_accuracy: 0.9874 - val_loss: 0.0457\n",
      "Epoch 8/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9978 - loss: 0.0090 - val_accuracy: 0.9840 - val_loss: 0.0600\n",
      "Epoch 9/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.9860 - val_loss: 0.0564\n",
      "Epoch 10/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.9876 - val_loss: 0.0479\n",
      "Epoch 11/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9852 - val_loss: 0.0626\n",
      "Epoch 12/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9865 - val_loss: 0.0583\n",
      "Epoch 13/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9880 - val_loss: 0.0522\n",
      "Epoch 14/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0062 - val_accuracy: 0.9892 - val_loss: 0.0502\n",
      "Epoch 15/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9880 - val_loss: 0.0547\n",
      "Epoch 16/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.9879 - val_loss: 0.0613\n",
      "Epoch 17/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9891 - val_loss: 0.0517\n",
      "Epoch 18/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9900 - val_loss: 0.0493\n",
      "Epoch 19/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9897 - val_loss: 0.0562\n",
      "Epoch 20/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9850 - val_loss: 0.0670\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0741\n",
      "\n",
      "Test score: 0.056367646902799606\n",
      "Test accuracy: 0.9868000149726868\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "\n",
    "#define the convnet \n",
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = models.Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(layers.Convolution2D(20, (5, 5), activation='relu',\n",
    "\t\t\tinput_shape=input_shape))\n",
    "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
    "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# Flatten => RELU layers\n",
    "\t\tmodel.add(layers.Flatten())\n",
    "\t\tmodel.add(layers.Dense(500, activation='relu'))\n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(layers.Dense(classes, activation=\"softmax\"))\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "VALIDATION_SPLIT=0.50\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# normalize\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# cast\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# use TensorBoard, princess Aurora!\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# fit \n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
    "\t\tcallbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
