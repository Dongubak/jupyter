{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 들어가며\n",
    "**머신러닝이란**\n",
    "머신러닝은 특정 작업을 위해 프로그래밍할 필요 없이 컴퓨터에게 학습 방법을 가리치는 데 중점을 둔 AI의 하위 분야다.\n",
    "\n",
    "## 머신러닝의 3가지 범주\n",
    "- `지도학습`은 기계에 입력 데이터와 원하는 출력이 제공되는 것으로서, 목표는 기계가 이전에 관찰한 적이 없는 데이터에 대해 의미 있는 예측을 할 수 있는 방식으로 이러한 교육 예제에서 학습하는 것이다.\n",
    "- `비지도 학습`은 기계에 입력 데이터만 제공되고 이후에 기계는 외부 지도나 입력 없이 자체적으로 의미 있는 구조를 찾는다.\n",
    "- `강화학습`은 기계가 환경과 상호 작용하는 에이전트 역할을 한다. 기계는 원하는 방식으로 행동하면 `보상`을, 원하지 않는 방식으로 행동하면 `처벌`을 받는다. 기계는 그에 따라 행동을 개발하는 방법을 학습해 보상 극대화를 시도한다.\n",
    "\n",
    "## 딥러닝의 역사\n",
    "딥러닝은 12년에 전 세계를 강타했다. 이때 챌린지는 손으로 라벨을 붙인 대규모 데이터셋의 하위 집합을 사용해 사진의 내용을 예측하는 것을 목표로하였다. 오류율 15.3%를 달성했으며 기술 산업 전반의 관심을 갖게 되었다.\n",
    "\n",
    "점점 더 많은 도메인에서 딥러닝 기술은 이전 방법으로 불가능했던 정확도 수준으로 문제를 해결할 수 있었다.\n",
    "\n",
    "이책은 먼저 간단한 모델로시작해 점점 더 정교한 모델을 점진적으로 도입한다."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장 Tensorflow와 신경망의 기초\n",
    "\n",
    "## 소개에서 제시한 1장의 내용\n",
    "- Tensorflow의 기본사항\n",
    "- 신경망, 딥러닝의 기초\n",
    "- 다양한 도구 소개\n",
    "\n",
    "\n",
    "## `Tensorflow(TF)`란 무엇인가\n",
    "Tensorflow는 Google Brain팀에서 심층 신경망을 위해 개발한 오픈 소스 소프트웨어 라이브러리이다. 15년 11월 아파치 2.0라이선스로 만들어져 빠르게 성장했고 인지도가 엄청나다.\n",
    "\n",
    "### 설명\n",
    "Google은 이를 머신 인텔리전스를 위한 오픈 소스 소프트웨어 라이브러리라고 부른다. 다른 딥러닝 라이브러리인 PyTorch, Caffe, MxNet은 Tensorflow와 같이 자동 미분, CPU/GPU 옵션, 사전에 훈련된 모델, 순환(recurrent)신경망, 컨볼루션(convolution)신경망, 심층 신뢰(belief)신경망 등의 NN아키텍처를 지원한다. 그럼에도 Tensorflow의 장점은 다음과 같다.\n",
    "\n",
    "- Tensorflow를 사용하면 모델을 배치하고 생산과정에서 쉽게 사용이 가능하다.\n",
    "- Tensorflow2.0에는 정적 그래프에 기반한 그래프 연산과 함께 즉시 연산(eager computation)지원이 도입됐다.\n",
    "- 강력한 커뮤니티의 지원을 받고 있다.\n",
    "\n",
    "## `Keras`란 무엇인가\n",
    "Keras는 딥러닝 모델을 만들고 훈련하기 위해 기초 구성 요소를 구성하는 유용한 API이다. -> Keras는 다양한 딥러닝 엔진에 통합할 수 있고 기초 구성요소를 구성하는 API이다.\n",
    "\n",
    "## `신경망`을 간단히 소개함\n",
    "신경망은 인간의 두뇌에서 영감을 얻은 방식으로 데이터를 처리하도록 컴퓨터를 가르치는 인공 지능 방식입니다. 인간의 두뇌와 비슷한 계층 구조로 상호 연결된 노드 또는 뉴런을 사용하는 딥 러닝이라고 불리는 기계 학습 과정의 유형입니다. 신경망은 컴퓨터가 실수에서 배우고 지속적으로 개선하는 데 사용하는 적응형 시스템을 생성합니다. 따라서 인공 신경망은 문서 요약 또는 얼굴 인식과 같은 복잡한 문제를 더 정확하게 해결하려고 합니다. (출처: https://aws.amazon.com/ko/what-is/neural-network/)\n",
    "\n",
    "### `퍼셉트론`이란\n",
    "퍼셉트론은 로젠 블렛이 1957년에 고안한 알고리즘이다. 퍼셉트론은 입력 데이터를 2개의 부류중 하나로 분류하는 분류기(classifier)이다. 퍼셉트론은 입력 특징 또는 간단히 특징이라 부르는 n개의 크기를 갖는 입력벡터가 주어지면 1또는 0을 출력하는 간단한 알고리즘이다.\n",
    "\n",
    "다음 그림은 간단한 퍼셉트론 예시이다.\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "위 식에서 $w_{1}x_{1}$은 가중치이며 $beta$는 b로 표현하는 bias이다.\n",
    "\n",
    "입력이 다음과 같다면\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "결국 벡터$**w** = (w_{1}, w_{2})$에 수직인 직선이 된다. 이를 3차원 공간에 표현하면\n",
    "$z = w_{1}x + w_{2}y + b$가 되며 이는 평면의 방정식을 찾는 것과 같다. 이 평면은 공간상의 4점을 분리하는 평면의 방정식이다.\n",
    "\n",
    "가중치 $w_{1}... w_{n}$ 들과 노드 $x_{1} ... x_{n}$ 끼리의 곱이 b보다 작거나 같은 경우 0 등으로 나타낸다.\n",
    "\n",
    "출처: https://compmath.korea.ac.kr/deeplearning/Perceptron.html\n",
    "\n",
    "## 다중 퍼셉트론 - 신경망 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4058 - loss: 1.9583 - val_accuracy: 0.8264 - val_loss: 0.7855\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8290 - loss: 0.6979 - val_accuracy: 0.8814 - val_loss: 0.4583\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8743 - loss: 0.4666 - val_accuracy: 0.9019 - val_loss: 0.3701\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8931 - loss: 0.3893 - val_accuracy: 0.9094 - val_loss: 0.3283\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.3474 - val_accuracy: 0.9169 - val_loss: 0.3027\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9102 - loss: 0.3187 - val_accuracy: 0.9212 - val_loss: 0.2838\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.3013 - val_accuracy: 0.9260 - val_loss: 0.2700\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2854 - val_accuracy: 0.9290 - val_loss: 0.2572\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.2716 - val_accuracy: 0.9317 - val_loss: 0.2491\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.2603 - val_accuracy: 0.9348 - val_loss: 0.2382\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.2484 - val_accuracy: 0.9366 - val_loss: 0.2303\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.2429 - val_accuracy: 0.9380 - val_loss: 0.2241\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.2284 - val_accuracy: 0.9404 - val_loss: 0.2162\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.2206 - val_accuracy: 0.9424 - val_loss: 0.2104\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9386 - loss: 0.2134 - val_accuracy: 0.9435 - val_loss: 0.2061\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.2053 - val_accuracy: 0.9443 - val_loss: 0.2003\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.1988 - val_accuracy: 0.9467 - val_loss: 0.1942\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.1938 - val_accuracy: 0.9476 - val_loss: 0.1913\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9450 - loss: 0.1899 - val_accuracy: 0.9489 - val_loss: 0.1866\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.1843 - val_accuracy: 0.9498 - val_loss: 0.1823\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1820 - val_accuracy: 0.9507 - val_loss: 0.1784\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.1722 - val_accuracy: 0.9515 - val_loss: 0.1755\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9512 - loss: 0.1706 - val_accuracy: 0.9520 - val_loss: 0.1725\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9542 - loss: 0.1603 - val_accuracy: 0.9532 - val_loss: 0.1687\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1592 - val_accuracy: 0.9543 - val_loss: 0.1657\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.1569 - val_accuracy: 0.9550 - val_loss: 0.1630\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9550 - loss: 0.1566 - val_accuracy: 0.9551 - val_loss: 0.1608\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.1574 - val_accuracy: 0.9564 - val_loss: 0.1577\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.1543 - val_accuracy: 0.9575 - val_loss: 0.1539\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1417 - val_accuracy: 0.9578 - val_loss: 0.1526\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9593 - loss: 0.1433 - val_accuracy: 0.9581 - val_loss: 0.1499\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9612 - loss: 0.1387 - val_accuracy: 0.9591 - val_loss: 0.1480\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.1347 - val_accuracy: 0.9604 - val_loss: 0.1460\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9648 - loss: 0.1249 - val_accuracy: 0.9612 - val_loss: 0.1436\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1306 - val_accuracy: 0.9605 - val_loss: 0.1427\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.1262 - val_accuracy: 0.9624 - val_loss: 0.1404\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.1233 - val_accuracy: 0.9625 - val_loss: 0.1385\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.1217 - val_accuracy: 0.9625 - val_loss: 0.1357\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1209 - val_accuracy: 0.9637 - val_loss: 0.1350\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9681 - loss: 0.1155 - val_accuracy: 0.9636 - val_loss: 0.1333\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.1120 - val_accuracy: 0.9646 - val_loss: 0.1312\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.1144 - val_accuracy: 0.9648 - val_loss: 0.1297\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1126 - val_accuracy: 0.9649 - val_loss: 0.1287\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1122 - val_accuracy: 0.9655 - val_loss: 0.1276\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9711 - loss: 0.1034 - val_accuracy: 0.9655 - val_loss: 0.1262\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.1066 - val_accuracy: 0.9657 - val_loss: 0.1248\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9717 - loss: 0.0990 - val_accuracy: 0.9663 - val_loss: 0.1227\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.0970 - val_accuracy: 0.9664 - val_loss: 0.1218\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.0959 - val_accuracy: 0.9656 - val_loss: 0.1214\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9744 - loss: 0.0953 - val_accuracy: 0.9673 - val_loss: 0.1193\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9621 - loss: 0.1327\n",
      "Test accuracy: 0.9664000272750854\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', \n",
    "   \t\tactivation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4357 - loss: 1.8960 - val_accuracy: 0.8320 - val_loss: 0.7591\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8406 - loss: 0.6747 - val_accuracy: 0.8864 - val_loss: 0.4525\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8774 - loss: 0.4622 - val_accuracy: 0.8983 - val_loss: 0.3714\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.3890 - val_accuracy: 0.9084 - val_loss: 0.3333\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9007 - loss: 0.3509 - val_accuracy: 0.9127 - val_loss: 0.3105\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9095 - loss: 0.3238 - val_accuracy: 0.9175 - val_loss: 0.2923\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9140 - loss: 0.3064 - val_accuracy: 0.9215 - val_loss: 0.2783\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2888 - val_accuracy: 0.9238 - val_loss: 0.2683\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9190 - loss: 0.2832 - val_accuracy: 0.9268 - val_loss: 0.2568\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.2670 - val_accuracy: 0.9288 - val_loss: 0.2486\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9247 - loss: 0.2634 - val_accuracy: 0.9310 - val_loss: 0.2408\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9280 - loss: 0.2518 - val_accuracy: 0.9327 - val_loss: 0.2349\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.2378 - val_accuracy: 0.9351 - val_loss: 0.2268\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.2337 - val_accuracy: 0.9371 - val_loss: 0.2217\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.2209 - val_accuracy: 0.9384 - val_loss: 0.2153\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.2183 - val_accuracy: 0.9406 - val_loss: 0.2108\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.2096 - val_accuracy: 0.9422 - val_loss: 0.2056\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.1987 - val_accuracy: 0.9433 - val_loss: 0.1999\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.1979 - val_accuracy: 0.9451 - val_loss: 0.1959\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9444 - loss: 0.1968 - val_accuracy: 0.9463 - val_loss: 0.1904\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9462 - loss: 0.1893 - val_accuracy: 0.9480 - val_loss: 0.1867\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.1822 - val_accuracy: 0.9488 - val_loss: 0.1823\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.1780 - val_accuracy: 0.9495 - val_loss: 0.1794\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.1751 - val_accuracy: 0.9500 - val_loss: 0.1747\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.1709 - val_accuracy: 0.9520 - val_loss: 0.1714\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9517 - loss: 0.1642 - val_accuracy: 0.9521 - val_loss: 0.1682\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1622 - val_accuracy: 0.9537 - val_loss: 0.1648\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1562 - val_accuracy: 0.9538 - val_loss: 0.1631\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9562 - loss: 0.1517 - val_accuracy: 0.9554 - val_loss: 0.1593\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.1501 - val_accuracy: 0.9564 - val_loss: 0.1573\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.1465 - val_accuracy: 0.9569 - val_loss: 0.1551\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.1409 - val_accuracy: 0.9566 - val_loss: 0.1530\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9611 - loss: 0.1393 - val_accuracy: 0.9575 - val_loss: 0.1496\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9627 - loss: 0.1321 - val_accuracy: 0.9573 - val_loss: 0.1478\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.1302 - val_accuracy: 0.9585 - val_loss: 0.1459\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9628 - loss: 0.1299 - val_accuracy: 0.9593 - val_loss: 0.1436\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9657 - loss: 0.1242 - val_accuracy: 0.9605 - val_loss: 0.1419\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1236 - val_accuracy: 0.9599 - val_loss: 0.1397\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9641 - loss: 0.1254 - val_accuracy: 0.9601 - val_loss: 0.1385\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 0.1185 - val_accuracy: 0.9614 - val_loss: 0.1380\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.1184 - val_accuracy: 0.9614 - val_loss: 0.1364\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9664 - loss: 0.1153 - val_accuracy: 0.9624 - val_loss: 0.1340\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9691 - loss: 0.1147 - val_accuracy: 0.9622 - val_loss: 0.1323\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1115 - val_accuracy: 0.9628 - val_loss: 0.1307\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9672 - loss: 0.1116 - val_accuracy: 0.9632 - val_loss: 0.1291\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9699 - loss: 0.1086 - val_accuracy: 0.9632 - val_loss: 0.1277\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.1029 - val_accuracy: 0.9643 - val_loss: 0.1272\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.1017 - val_accuracy: 0.9640 - val_loss: 0.1267\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.0951 - val_accuracy: 0.9651 - val_loss: 0.1244\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.1011 - val_accuracy: 0.9643 - val_loss: 0.1228\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9607 - loss: 0.1340\n",
      "Test accuracy: 0.9661999940872192\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3213 - loss: 2.0217 - val_accuracy: 0.7983 - val_loss: 0.9181\n",
      "Epoch 2/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6772 - loss: 1.0405 - val_accuracy: 0.8581 - val_loss: 0.5544\n",
      "Epoch 3/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.7552 - val_accuracy: 0.8827 - val_loss: 0.4389\n",
      "Epoch 4/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8081 - loss: 0.6226 - val_accuracy: 0.8940 - val_loss: 0.3813\n",
      "Epoch 5/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8315 - loss: 0.5607 - val_accuracy: 0.9015 - val_loss: 0.3472\n",
      "Epoch 6/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8455 - loss: 0.5163 - val_accuracy: 0.9083 - val_loss: 0.3217\n",
      "Epoch 7/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8608 - loss: 0.4723 - val_accuracy: 0.9133 - val_loss: 0.3010\n",
      "Epoch 8/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8691 - loss: 0.4498 - val_accuracy: 0.9166 - val_loss: 0.2866\n",
      "Epoch 9/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8741 - loss: 0.4257 - val_accuracy: 0.9206 - val_loss: 0.2730\n",
      "Epoch 10/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8793 - loss: 0.4126 - val_accuracy: 0.9255 - val_loss: 0.2610\n",
      "Epoch 11/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.3880 - val_accuracy: 0.9267 - val_loss: 0.2521\n",
      "Epoch 12/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8883 - loss: 0.3819 - val_accuracy: 0.9293 - val_loss: 0.2423\n",
      "Epoch 13/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8921 - loss: 0.3614 - val_accuracy: 0.9323 - val_loss: 0.2339\n",
      "Epoch 14/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.3519 - val_accuracy: 0.9337 - val_loss: 0.2273\n",
      "Epoch 15/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8991 - loss: 0.3393 - val_accuracy: 0.9358 - val_loss: 0.2192\n",
      "Epoch 16/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9045 - loss: 0.3223 - val_accuracy: 0.9379 - val_loss: 0.2138\n",
      "Epoch 17/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9039 - loss: 0.3237 - val_accuracy: 0.9393 - val_loss: 0.2079\n",
      "Epoch 18/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.3111 - val_accuracy: 0.9408 - val_loss: 0.2029\n",
      "Epoch 19/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.3026 - val_accuracy: 0.9424 - val_loss: 0.1976\n",
      "Epoch 20/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9124 - loss: 0.2948 - val_accuracy: 0.9431 - val_loss: 0.1935\n",
      "Epoch 21/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 0.2874 - val_accuracy: 0.9434 - val_loss: 0.1895\n",
      "Epoch 22/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9162 - loss: 0.2819 - val_accuracy: 0.9453 - val_loss: 0.1849\n",
      "Epoch 23/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9183 - loss: 0.2765 - val_accuracy: 0.9466 - val_loss: 0.1810\n",
      "Epoch 24/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9207 - loss: 0.2646 - val_accuracy: 0.9477 - val_loss: 0.1786\n",
      "Epoch 25/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9223 - loss: 0.2596 - val_accuracy: 0.9488 - val_loss: 0.1742\n",
      "Epoch 26/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2692 - val_accuracy: 0.9502 - val_loss: 0.1711\n",
      "Epoch 27/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.2534 - val_accuracy: 0.9512 - val_loss: 0.1687\n",
      "Epoch 28/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.2500 - val_accuracy: 0.9515 - val_loss: 0.1654\n",
      "Epoch 29/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9293 - loss: 0.2411 - val_accuracy: 0.9523 - val_loss: 0.1629\n",
      "Epoch 30/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9251 - loss: 0.2470 - val_accuracy: 0.9531 - val_loss: 0.1597\n",
      "Epoch 31/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9294 - loss: 0.2419 - val_accuracy: 0.9537 - val_loss: 0.1572\n",
      "Epoch 32/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9297 - loss: 0.2323 - val_accuracy: 0.9544 - val_loss: 0.1554\n",
      "Epoch 33/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9334 - loss: 0.2344 - val_accuracy: 0.9556 - val_loss: 0.1529\n",
      "Epoch 34/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.2226 - val_accuracy: 0.9557 - val_loss: 0.1509\n",
      "Epoch 35/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.2279 - val_accuracy: 0.9557 - val_loss: 0.1487\n",
      "Epoch 36/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9349 - loss: 0.2198 - val_accuracy: 0.9569 - val_loss: 0.1470\n",
      "Epoch 37/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9352 - loss: 0.2149 - val_accuracy: 0.9571 - val_loss: 0.1452\n",
      "Epoch 38/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9352 - loss: 0.2200 - val_accuracy: 0.9578 - val_loss: 0.1440\n",
      "Epoch 39/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.2076 - val_accuracy: 0.9577 - val_loss: 0.1424\n",
      "Epoch 40/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.2097 - val_accuracy: 0.9586 - val_loss: 0.1408\n",
      "Epoch 41/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9377 - loss: 0.2094 - val_accuracy: 0.9592 - val_loss: 0.1396\n",
      "Epoch 42/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.2039 - val_accuracy: 0.9597 - val_loss: 0.1382\n",
      "Epoch 43/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.2020 - val_accuracy: 0.9601 - val_loss: 0.1363\n",
      "Epoch 44/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9416 - loss: 0.2021 - val_accuracy: 0.9605 - val_loss: 0.1346\n",
      "Epoch 45/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9424 - loss: 0.1964 - val_accuracy: 0.9607 - val_loss: 0.1337\n",
      "Epoch 46/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.1940 - val_accuracy: 0.9609 - val_loss: 0.1323\n",
      "Epoch 47/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.1935 - val_accuracy: 0.9613 - val_loss: 0.1314\n",
      "Epoch 48/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1885 - val_accuracy: 0.9613 - val_loss: 0.1308\n",
      "Epoch 49/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9454 - loss: 0.1875 - val_accuracy: 0.9619 - val_loss: 0.1294\n",
      "Epoch 50/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.1926 - val_accuracy: 0.9623 - val_loss: 0.1282\n",
      "Epoch 51/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.1826 - val_accuracy: 0.9624 - val_loss: 0.1270\n",
      "Epoch 52/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9473 - loss: 0.1748 - val_accuracy: 0.9628 - val_loss: 0.1262\n",
      "Epoch 53/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1778 - val_accuracy: 0.9637 - val_loss: 0.1240\n",
      "Epoch 54/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1764 - val_accuracy: 0.9638 - val_loss: 0.1241\n",
      "Epoch 55/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1763 - val_accuracy: 0.9638 - val_loss: 0.1230\n",
      "Epoch 56/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9475 - loss: 0.1752 - val_accuracy: 0.9640 - val_loss: 0.1224\n",
      "Epoch 57/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.1741 - val_accuracy: 0.9646 - val_loss: 0.1207\n",
      "Epoch 58/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1701 - val_accuracy: 0.9645 - val_loss: 0.1199\n",
      "Epoch 59/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9502 - loss: 0.1664 - val_accuracy: 0.9648 - val_loss: 0.1189\n",
      "Epoch 60/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.1726 - val_accuracy: 0.9646 - val_loss: 0.1180\n",
      "Epoch 61/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9503 - loss: 0.1658 - val_accuracy: 0.9649 - val_loss: 0.1182\n",
      "Epoch 62/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1605 - val_accuracy: 0.9658 - val_loss: 0.1167\n",
      "Epoch 63/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9530 - loss: 0.1578 - val_accuracy: 0.9653 - val_loss: 0.1159\n",
      "Epoch 64/200\n",
      "\u001b[1m292/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.1602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     55\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#training the moodel\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#evalute the model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the moodel\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evalute the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_1 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_4 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_5 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3115 - loss: 2.1302 - val_accuracy: 0.8166 - val_loss: 0.8805\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8142 - loss: 0.7316 - val_accuracy: 0.8815 - val_loss: 0.4336\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8849 - loss: 0.4231 - val_accuracy: 0.9028 - val_loss: 0.3488\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9022 - loss: 0.3492 - val_accuracy: 0.9137 - val_loss: 0.3058\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9114 - loss: 0.3110 - val_accuracy: 0.9226 - val_loss: 0.2758\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9198 - loss: 0.2798 - val_accuracy: 0.9277 - val_loss: 0.2582\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9222 - loss: 0.2692 - val_accuracy: 0.9283 - val_loss: 0.2466\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2458 - val_accuracy: 0.9335 - val_loss: 0.2311\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9337 - loss: 0.2314 - val_accuracy: 0.9376 - val_loss: 0.2217\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.2092 - val_accuracy: 0.9418 - val_loss: 0.2102\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.2047 - val_accuracy: 0.9441 - val_loss: 0.2027\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1909 - val_accuracy: 0.9440 - val_loss: 0.1915\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9454 - loss: 0.1869 - val_accuracy: 0.9469 - val_loss: 0.1831\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9488 - loss: 0.1741 - val_accuracy: 0.9499 - val_loss: 0.1767\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.1688 - val_accuracy: 0.9517 - val_loss: 0.1710\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.1590 - val_accuracy: 0.9526 - val_loss: 0.1691\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.1565 - val_accuracy: 0.9535 - val_loss: 0.1641\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1434 - val_accuracy: 0.9553 - val_loss: 0.1565\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.1375 - val_accuracy: 0.9573 - val_loss: 0.1527\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1317 - val_accuracy: 0.9586 - val_loss: 0.1478\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.1276 - val_accuracy: 0.9602 - val_loss: 0.1430\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9624 - loss: 0.1285 - val_accuracy: 0.9604 - val_loss: 0.1422\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9645 - loss: 0.1192 - val_accuracy: 0.9592 - val_loss: 0.1436\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9657 - loss: 0.1172 - val_accuracy: 0.9607 - val_loss: 0.1387\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9674 - loss: 0.1124 - val_accuracy: 0.9617 - val_loss: 0.1350\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9679 - loss: 0.1094 - val_accuracy: 0.9624 - val_loss: 0.1341\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0997 - val_accuracy: 0.9638 - val_loss: 0.1296\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9708 - loss: 0.0999 - val_accuracy: 0.9609 - val_loss: 0.1370\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.0982 - val_accuracy: 0.9650 - val_loss: 0.1272\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9746 - loss: 0.0926 - val_accuracy: 0.9650 - val_loss: 0.1259\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.0892 - val_accuracy: 0.9645 - val_loss: 0.1221\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.0898 - val_accuracy: 0.9656 - val_loss: 0.1209\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.0844 - val_accuracy: 0.9663 - val_loss: 0.1207\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0816 - val_accuracy: 0.9660 - val_loss: 0.1188\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0822 - val_accuracy: 0.9667 - val_loss: 0.1174\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0756 - val_accuracy: 0.9669 - val_loss: 0.1158\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0771 - val_accuracy: 0.9668 - val_loss: 0.1171\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0727 - val_accuracy: 0.9667 - val_loss: 0.1152\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9802 - loss: 0.0709 - val_accuracy: 0.9668 - val_loss: 0.1167\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0693 - val_accuracy: 0.9678 - val_loss: 0.1114\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0680 - val_accuracy: 0.9692 - val_loss: 0.1115\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0675 - val_accuracy: 0.9669 - val_loss: 0.1119\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0645 - val_accuracy: 0.9693 - val_loss: 0.1114\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0646 - val_accuracy: 0.9691 - val_loss: 0.1097\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0592 - val_accuracy: 0.9689 - val_loss: 0.1100\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0577 - val_accuracy: 0.9681 - val_loss: 0.1100\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0547 - val_accuracy: 0.9687 - val_loss: 0.1096\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0539 - val_accuracy: 0.9698 - val_loss: 0.1068\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0517 - val_accuracy: 0.9692 - val_loss: 0.1076\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0500 - val_accuracy: 0.9698 - val_loss: 0.1073\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9648 - loss: 0.1107\n",
      "Test accuracy: 0.9708999991416931\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step\n"
     ]
    }
   ],
   "source": [
    "### 연습문제 은닉층 추가\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_1', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_4', activation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer_5', \n",
    "   \t\tactivation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4584 - loss: 1.8861 - val_accuracy: 0.8475 - val_loss: 0.7245\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8453 - loss: 0.6566 - val_accuracy: 0.8889 - val_loss: 0.4333\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8827 - loss: 0.4444 - val_accuracy: 0.9018 - val_loss: 0.3588\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8935 - loss: 0.3849 - val_accuracy: 0.9071 - val_loss: 0.3235\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9033 - loss: 0.3424 - val_accuracy: 0.9132 - val_loss: 0.3031\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9077 - loss: 0.3228 - val_accuracy: 0.9183 - val_loss: 0.2879\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.3008 - val_accuracy: 0.9212 - val_loss: 0.2742\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.2919 - val_accuracy: 0.9262 - val_loss: 0.2625\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.2726 - val_accuracy: 0.9285 - val_loss: 0.2523\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9267 - loss: 0.2633 - val_accuracy: 0.9316 - val_loss: 0.2436\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.2544 - val_accuracy: 0.9333 - val_loss: 0.2364\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9315 - loss: 0.2388 - val_accuracy: 0.9351 - val_loss: 0.2294\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9329 - loss: 0.2363 - val_accuracy: 0.9357 - val_loss: 0.2238\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.2276 - val_accuracy: 0.9395 - val_loss: 0.2159\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9380 - loss: 0.2185 - val_accuracy: 0.9408 - val_loss: 0.2120\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9387 - loss: 0.2141 - val_accuracy: 0.9410 - val_loss: 0.2068\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9386 - loss: 0.2093 - val_accuracy: 0.9436 - val_loss: 0.2022\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9411 - loss: 0.2059 - val_accuracy: 0.9446 - val_loss: 0.1961\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.1951 - val_accuracy: 0.9463 - val_loss: 0.1923\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.1954 - val_accuracy: 0.9478 - val_loss: 0.1887\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.1920 - val_accuracy: 0.9488 - val_loss: 0.1840\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9479 - loss: 0.1821 - val_accuracy: 0.9492 - val_loss: 0.1805\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.1803 - val_accuracy: 0.9502 - val_loss: 0.1771\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1716 - val_accuracy: 0.9522 - val_loss: 0.1739\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.1667 - val_accuracy: 0.9528 - val_loss: 0.1717\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1619 - val_accuracy: 0.9533 - val_loss: 0.1685\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1589 - val_accuracy: 0.9533 - val_loss: 0.1652\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1528 - val_accuracy: 0.9549 - val_loss: 0.1623\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9573 - loss: 0.1520 - val_accuracy: 0.9550 - val_loss: 0.1597\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1473 - val_accuracy: 0.9555 - val_loss: 0.1568\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9585 - loss: 0.1469 - val_accuracy: 0.9562 - val_loss: 0.1554\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9596 - loss: 0.1423 - val_accuracy: 0.9572 - val_loss: 0.1521\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.1420 - val_accuracy: 0.9585 - val_loss: 0.1501\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.1347 - val_accuracy: 0.9593 - val_loss: 0.1480\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.1327 - val_accuracy: 0.9597 - val_loss: 0.1455\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1340 - val_accuracy: 0.9603 - val_loss: 0.1439\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1286 - val_accuracy: 0.9600 - val_loss: 0.1437\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9648 - loss: 0.1260 - val_accuracy: 0.9617 - val_loss: 0.1404\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9654 - loss: 0.1213 - val_accuracy: 0.9621 - val_loss: 0.1381\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1218 - val_accuracy: 0.9607 - val_loss: 0.1385\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.1199 - val_accuracy: 0.9632 - val_loss: 0.1350\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1145 - val_accuracy: 0.9623 - val_loss: 0.1336\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9686 - loss: 0.1136 - val_accuracy: 0.9631 - val_loss: 0.1329\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.1091 - val_accuracy: 0.9635 - val_loss: 0.1305\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9714 - loss: 0.1070 - val_accuracy: 0.9636 - val_loss: 0.1301\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9688 - loss: 0.1118 - val_accuracy: 0.9643 - val_loss: 0.1282\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9717 - loss: 0.1049 - val_accuracy: 0.9642 - val_loss: 0.1277\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9713 - loss: 0.1052 - val_accuracy: 0.9652 - val_loss: 0.1260\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.0986 - val_accuracy: 0.9656 - val_loss: 0.1243\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.1049 - val_accuracy: 0.9657 - val_loss: 0.1229\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9566 - loss: 0.1373\n",
      "Test accuracy: 0.9632999897003174\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3054 - loss: 2.0222 - val_accuracy: 0.8287 - val_loss: 0.9182\n",
      "Epoch 2/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6900 - loss: 1.0236 - val_accuracy: 0.8724 - val_loss: 0.5230\n",
      "Epoch 3/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7788 - loss: 0.7215 - val_accuracy: 0.8892 - val_loss: 0.4217\n",
      "Epoch 4/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8153 - loss: 0.6129 - val_accuracy: 0.8994 - val_loss: 0.3716\n",
      "Epoch 5/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8364 - loss: 0.5441 - val_accuracy: 0.9073 - val_loss: 0.3407\n",
      "Epoch 6/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8500 - loss: 0.4991 - val_accuracy: 0.9120 - val_loss: 0.3156\n",
      "Epoch 7/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8603 - loss: 0.4677 - val_accuracy: 0.9158 - val_loss: 0.2993\n",
      "Epoch 8/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.4411 - val_accuracy: 0.9191 - val_loss: 0.2845\n",
      "Epoch 9/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8775 - loss: 0.4163 - val_accuracy: 0.9218 - val_loss: 0.2719\n",
      "Epoch 10/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8813 - loss: 0.3999 - val_accuracy: 0.9251 - val_loss: 0.2602\n",
      "Epoch 11/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.3787 - val_accuracy: 0.9268 - val_loss: 0.2514\n",
      "Epoch 12/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.3678 - val_accuracy: 0.9308 - val_loss: 0.2433\n",
      "Epoch 13/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8972 - loss: 0.3542 - val_accuracy: 0.9325 - val_loss: 0.2343\n",
      "Epoch 14/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8990 - loss: 0.3418 - val_accuracy: 0.9337 - val_loss: 0.2277\n",
      "Epoch 15/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9006 - loss: 0.3350 - val_accuracy: 0.9359 - val_loss: 0.2208\n",
      "Epoch 16/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.3195 - val_accuracy: 0.9388 - val_loss: 0.2133\n",
      "Epoch 17/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9058 - loss: 0.3155 - val_accuracy: 0.9404 - val_loss: 0.2095\n",
      "Epoch 18/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9110 - loss: 0.3026 - val_accuracy: 0.9423 - val_loss: 0.2031\n",
      "Epoch 19/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9135 - loss: 0.2951 - val_accuracy: 0.9431 - val_loss: 0.1986\n",
      "Epoch 20/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9140 - loss: 0.2894 - val_accuracy: 0.9441 - val_loss: 0.1944\n",
      "Epoch 21/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9174 - loss: 0.2831 - val_accuracy: 0.9445 - val_loss: 0.1906\n",
      "Epoch 22/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9198 - loss: 0.2741 - val_accuracy: 0.9463 - val_loss: 0.1853\n",
      "Epoch 23/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.2697 - val_accuracy: 0.9480 - val_loss: 0.1813\n",
      "Epoch 24/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9212 - loss: 0.2656 - val_accuracy: 0.9487 - val_loss: 0.1784\n",
      "Epoch 25/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9228 - loss: 0.2629 - val_accuracy: 0.9495 - val_loss: 0.1750\n",
      "Epoch 26/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9270 - loss: 0.2553 - val_accuracy: 0.9502 - val_loss: 0.1717\n",
      "Epoch 27/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9256 - loss: 0.2514 - val_accuracy: 0.9503 - val_loss: 0.1682\n",
      "Epoch 28/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9288 - loss: 0.2428 - val_accuracy: 0.9511 - val_loss: 0.1652\n",
      "Epoch 29/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.2465 - val_accuracy: 0.9519 - val_loss: 0.1628\n",
      "Epoch 30/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.2379 - val_accuracy: 0.9528 - val_loss: 0.1606\n",
      "Epoch 31/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.2310 - val_accuracy: 0.9532 - val_loss: 0.1586\n",
      "Epoch 32/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.2378 - val_accuracy: 0.9545 - val_loss: 0.1556\n",
      "Epoch 33/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.2204 - val_accuracy: 0.9548 - val_loss: 0.1535\n",
      "Epoch 34/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.2258 - val_accuracy: 0.9549 - val_loss: 0.1515\n",
      "Epoch 35/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9371 - loss: 0.2218 - val_accuracy: 0.9557 - val_loss: 0.1491\n",
      "Epoch 36/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9392 - loss: 0.2057 - val_accuracy: 0.9566 - val_loss: 0.1476\n",
      "Epoch 37/200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.2145 - val_accuracy: 0.9567 - val_loss: 0.1451\n",
      "Epoch 38/200\n",
      "\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9390 - loss: 0.2096"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 59\u001b[0m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     55\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#training the moodel\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#evalute the model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:339\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    330\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    331\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 339\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    351\u001b[0m }\n\u001b[1;32m    352\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:425\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    424\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 425\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    427\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the moodel\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evalute the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7533 - loss: 0.7884 - val_accuracy: 0.9473 - val_loss: 0.1864\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9253 - loss: 0.2463 - val_accuracy: 0.9585 - val_loss: 0.1404\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9456 - loss: 0.1838 - val_accuracy: 0.9652 - val_loss: 0.1168\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9494 - loss: 0.1616 - val_accuracy: 0.9675 - val_loss: 0.1097\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9593 - loss: 0.1360 - val_accuracy: 0.9699 - val_loss: 0.1021\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.1179 - val_accuracy: 0.9706 - val_loss: 0.1009\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9669 - loss: 0.1109 - val_accuracy: 0.9743 - val_loss: 0.0966\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.1036 - val_accuracy: 0.9742 - val_loss: 0.0957\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9707 - loss: 0.0974 - val_accuracy: 0.9753 - val_loss: 0.0960\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9713 - loss: 0.0919 - val_accuracy: 0.9760 - val_loss: 0.0940\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.1052\n",
      "Test accuracy: 0.9775999784469604\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "#for tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard_callback = TensorBoard('.logdir')\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='RMSProp', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the moodel\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
    "\t\tcallbacks=[tensorboard_callback])\n",
    "\n",
    "#evalute the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7206 - loss: 0.8774 - val_accuracy: 0.9448 - val_loss: 0.1832\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9262 - loss: 0.2539 - val_accuracy: 0.9610 - val_loss: 0.1322\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9445 - loss: 0.1842 - val_accuracy: 0.9681 - val_loss: 0.1086\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9552 - loss: 0.1477 - val_accuracy: 0.9695 - val_loss: 0.1020\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9583 - loss: 0.1321 - val_accuracy: 0.9718 - val_loss: 0.0950\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9653 - loss: 0.1155 - val_accuracy: 0.9758 - val_loss: 0.0890\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.1010 - val_accuracy: 0.9753 - val_loss: 0.0849\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.0956 - val_accuracy: 0.9754 - val_loss: 0.0828\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9720 - loss: 0.0891 - val_accuracy: 0.9758 - val_loss: 0.0818\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.0823 - val_accuracy: 0.9768 - val_loss: 0.0798\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0858\n",
      "Test accuracy: 0.9796000123023987\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "#for tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard_callback = TensorBoard('.logdir')\n",
    "\n",
    "# network and training\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# loading MNIST dataset\n",
    "# verify\n",
    "# the split between train and test is 60,000, and 10,000 respectly \n",
    "# one-hot is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalize in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tinput_shape=(RESHAPED,),\n",
    "   \t\tname='dense_layer', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "   \t\tname='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "   \t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='Adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the moodel\n",
    "model.fit(X_train, Y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
    "\t\tcallbacks=[tensorboard_callback])\n",
    "\n",
    "#evalute the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# making prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5730 - loss: 0.6810 - val_accuracy: 0.8187 - val_loss: 0.5772\n",
      "Epoch 2/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8184 - loss: 0.4733 - val_accuracy: 0.8560 - val_loss: 0.3474\n",
      "Epoch 3/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8804 - loss: 0.2903 - val_accuracy: 0.8707 - val_loss: 0.3082\n",
      "Epoch 4/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9143 - loss: 0.2244 - val_accuracy: 0.8769 - val_loss: 0.2939\n",
      "Epoch 5/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9337 - loss: 0.1811 - val_accuracy: 0.8768 - val_loss: 0.2899\n",
      "Epoch 6/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9493 - loss: 0.1419 - val_accuracy: 0.8759 - val_loss: 0.2930\n",
      "Epoch 7/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9659 - loss: 0.1103 - val_accuracy: 0.8701 - val_loss: 0.3051\n",
      "Epoch 8/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9778 - loss: 0.0824 - val_accuracy: 0.8686 - val_loss: 0.3136\n",
      "Epoch 9/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9828 - loss: 0.0635 - val_accuracy: 0.8644 - val_loss: 0.3290\n",
      "Epoch 10/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9893 - loss: 0.0472 - val_accuracy: 0.8607 - val_loss: 0.3480\n",
      "Epoch 11/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9930 - loss: 0.0355 - val_accuracy: 0.8588 - val_loss: 0.3637\n",
      "Epoch 12/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9946 - loss: 0.0256 - val_accuracy: 0.8584 - val_loss: 0.3807\n",
      "Epoch 13/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0198 - val_accuracy: 0.8563 - val_loss: 0.3976\n",
      "Epoch 14/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9971 - loss: 0.0187 - val_accuracy: 0.8546 - val_loss: 0.4124\n",
      "Epoch 15/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9974 - loss: 0.0141 - val_accuracy: 0.8538 - val_loss: 0.4284\n",
      "Epoch 16/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9989 - loss: 0.0105 - val_accuracy: 0.8545 - val_loss: 0.4414\n",
      "Epoch 17/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9986 - loss: 0.0096 - val_accuracy: 0.8534 - val_loss: 0.4540\n",
      "Epoch 18/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9985 - loss: 0.0098 - val_accuracy: 0.8525 - val_loss: 0.4691\n",
      "Epoch 19/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9990 - loss: 0.0064 - val_accuracy: 0.8502 - val_loss: 0.4897\n",
      "Epoch 20/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0068 - val_accuracy: 0.8517 - val_loss: 0.4904\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.4843\n",
      "\n",
      "Test score: 0.49040380120277405\n",
      "Test accuracy: 0.8516799807548523\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "max_len = 200\n",
    "n_words = 10000\n",
    "dim_embedding = 256\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE =500\n",
    "\n",
    "def load_data():\n",
    "\t#load data\n",
    "\t(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
    "\t# Pad sequences with max_len\n",
    "\tX_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "\tX_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "\treturn (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "def build_model():\n",
    "\tmodel = models.Sequential()\n",
    "\t#Input - Emedding Layer\n",
    "\t# the model will take as input an integer matrix of size (batch, input_length)\n",
    "\t# the model will output dimension (input_length, dim_embedding)\n",
    "    # the largest integer in the input should be no larger\n",
    "    # than n_words (vocabulary size).\n",
    "\tmodel.add(layers.Embedding(n_words, \n",
    "\t\tdim_embedding, input_length=max_len))\n",
    "\n",
    "\tmodel.add(layers.Dropout(0.3))\n",
    "\n",
    "\t#takes the maximum value of either feature vector from each of the n_words features\n",
    "\tmodel.add(layers.GlobalMaxPooling1D())\n",
    "\tmodel.add(layers.Dense(128, activation='relu'))\n",
    "\tmodel.add(layers.Dropout(0.5))\n",
    "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\treturn model\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "model=build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs= EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
